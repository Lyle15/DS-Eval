{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08d5aa0e",
   "metadata": {},
   "source": [
    "Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "id": "0fa73131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d40cbb",
   "metadata": {},
   "source": [
    "Import given .csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "id": "f317c2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_fields_df = pd.read_csv('reference_fileds.csv')\n",
    "reference_securities_df = pd.read_csv('reference_securities.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f22e6d",
   "metadata": {},
   "source": [
    "Import the given .dif file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "id": "a0ec21f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('corp_pfd.dif') as file:\n",
    "    corp_pfd = file.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881cfc4c",
   "metadata": {},
   "source": [
    "Save an array of the file names that will be used. Per the instructions, this will be between the 'START-OF-FIELDS' and 'END-OF-FIELDS' string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9068533f",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d56ea0",
   "metadata": {},
   "source": [
    "I will be first be examining the files to make sure that my logic to parse the code will work as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "id": "c4710f52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['START-OF-FILE\\n',\n",
       " 'PROGRAMNAME=getdata\\n',\n",
       " 'DATEFORMAT=yyyymmdd\\n',\n",
       " '\\n',\n",
       " 'START-OF-FIELDS\\n']"
      ]
     },
     "execution_count": 792,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the column names and notice the \"\\n\"\n",
    "corp_pfd[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9397dd34",
   "metadata": {},
   "source": [
    "I will strip the new line character for determing column names, and will save the changes in a new list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "id": "9248cdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "corp_pfd_stripped = []\n",
    "for x in corp_pfd:\n",
    "    #Validate the new line character only occurs once per list item\n",
    "    if x.count('/n') > 1:\n",
    "        print('ERROR: ', x, ' has more than 1 new line character')\n",
    "    \n",
    "    corp_pfd_stripped.append(x.rstrip('\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40552296",
   "metadata": {},
   "source": [
    "Validate that the 'START-OF-FIELDS' and 'END-OF-FIELDS' strings only exist once to avoid any code issues (both need to return 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "id": "9505ca38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(corp_pfd_stripped.count('START-OF-FIELDS'))\n",
    "print(corp_pfd_stripped.count('END-OF-FIELDS'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671b4044",
   "metadata": {},
   "source": [
    "Extract the column names into the list\n",
    "'col_names'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "id": "16406942",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine where the column fields are located\n",
    "col_name_start = corp_pfd_stripped.index('START-OF-FIELDS')\n",
    "col_name_end = corp_pfd_stripped.index('END-OF-FIELDS')\n",
    "col_names = []\n",
    "for idx, col in enumerate(corp_pfd_stripped):\n",
    "    #ignore comments and new lines, as they are not relevant\n",
    "    if idx > col_name_start and idx < col_name_end and len(col) != 0 and col[0] != '#':\n",
    "        col_names.append(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c91ebd",
   "metadata": {},
   "source": [
    "We will now read in the data for step 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fbb82d",
   "metadata": {},
   "source": [
    "### Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "id": "0a75357a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_start = corp_pfd.index('START-OF-DATA\\n') + 1\n",
    "data_end = corp_pfd.index('END-OF-DATA\\n') - 1\n",
    "data_list = corp_pfd[data_start:data_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "id": "d6b0c233",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Any FutureWarnings are unnecesary for this purpose, adding for quicker performance\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category = FutureWarning)\n",
    "\n",
    "#parse data by the '|' delimiter\n",
    "test = data_list[0].split('|')\n",
    "step_1_df = pd.DataFrame()\n",
    "for data in data_list:\n",
    "    split_data = data.split('|')\n",
    "    #remove the \\n that signifies the end of the data line\n",
    "    split_data = split_data[:len(split_data) - 1]\n",
    "    #Convert to series so that it can be appended\n",
    "    split_data_df = pd.Series(split_data)\n",
    "    step_1_df = step_1_df.append(split_data_df, ignore_index = True)\n",
    "    \n",
    "#Name columns that we determined above when extracting the column names\n",
    "step_1_df.columns = col_names\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f983e1",
   "metadata": {},
   "source": [
    "### Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "id": "f7ea5a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_fields_uppercase = []\n",
    "reference_fields_df\n",
    "for x in reference_fields_df['field']:\n",
    "    #If the column isn't in the new list, we'll skip it\n",
    "    if x.upper()in col_names:\n",
    "        #Add all the columns from the reference field as uppercase values\n",
    "        reference_fields_uppercase.append(x.upper())\n",
    "#Trim our dataframe so that it has only the columns found in the 'reference_fields.csv' file\n",
    "step_2_df = step_1_df[reference_fields_uppercase]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82dbf437",
   "metadata": {},
   "source": [
    "### Step 3 part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "id": "5dc2482d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For part 1 we will identify the securities that are not found in reference_securities_csv (part 2 will format this dataframe)\n",
    "\n",
    "new_securities = []\n",
    "\n",
    "for idx, x in step_2_df.iterrows():\n",
    "    #If a securitity exists in our parsed data, but not the reference_security file, we will save the id_bb_global\n",
    "    if not reference_securities_df['id_bb_global'].str.contains(x['ID_BB_GLOBAL']).any():\n",
    "        new_securities.append(x['ID_BB_GLOBAL'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82423245",
   "metadata": {},
   "source": [
    "## Step 3 part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503f8058",
   "metadata": {},
   "source": [
    "Find the rows for the ID_BB_GLOBAL values that are found in the input file but not in the reference securities csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "id": "0ee6dfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_3_df = step_2_df[step_2_df['ID_BB_GLOBAL'].isin(new_securities)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013493eb",
   "metadata": {},
   "source": [
    "Change the column names so that they match the columns of reference_securities.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "id": "033921a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_securities_df_upper = []\n",
    "for x in reference_securities_df.columns:\n",
    "    #reference_securities columns are lowercase, we will make them uppercase to make them easier to compare\n",
    "    reference_securities_df_upper.append(x.upper())\n",
    "step_3_df = pd.DataFrame(step_1_df, columns = reference_securities_df_upper)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "id": "1708be57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ID_BB_GLOBAL       ID_ISIN   ID_CUSIP ID_SEDOL1  TICKER  \\\n",
      "0     BBG00KRL8RW6  HK0000416609  AS3629704   BJGV5B5    MTRC   \n",
      "1     BBG00KRMSZ63  ARCILB560016  AS3764410            CILBAR   \n",
      "2     BBG00NZ74Q67  XS1989092116  ZS2774298   BJK3NS0  REDPRO   \n",
      "3     BBG00000F4P6  CA4590568X88  4590568X8              IBRD   \n",
      "4     BBG009HTFZR5  US400489AH37  400489AH3   BYY0995  POSADA   \n",
      "...            ...           ...        ...       ...     ...   \n",
      "2890  BBG00P8S59R0  XS2004865957  ZS8316854              ITAU   \n",
      "2891  BBG00P8SNLL9  US90346JAC62  90346JAC6            USJACU   \n",
      "2892  BBG00P8SXNZ9  USP9634CAC57  ZS8402340   BJYJF77  USJACU   \n",
      "2893  BBG00P96HDD0                ZS8705577             LTMCI   \n",
      "2894  BBG00P9C1MJ8                ZS8952088            SECUCL   \n",
      "\n",
      "                         NAME     EXCH_CODE                   ISSUER  \\\n",
      "0             MTR CORP CI LTD    NOT LISTED          MTR CORP CI LTD   \n",
      "1                CILBRAKE SRL  BUENOS AIRES             CILBRAKE SRL   \n",
      "2      REDCO PROPERTIES GROUP        SGX-ST   REDCO PROPERTIES GROUP   \n",
      "3     INTL BK RECON & DEVELOP    NOT LISTED  INTL BK RECON & DEVELOP   \n",
      "4        GRUPO POSADAS SAB CV         TRACE     GRUPO POSADAS SAB CV   \n",
      "...                       ...           ...                      ...   \n",
      "2890  ITAU UNIBANCO SA/NASSAU    NOT LISTED  ITAU UNIBANCO SA/NASSAU   \n",
      "2891   USJ ACUCAR E ALCOOL SA         TRACE   USJ ACUCAR E ALCOOL SA   \n",
      "2892   USJ ACUCAR E ALCOOL SA         TRACE   USJ ACUCAR E ALCOOL SA   \n",
      "2893  LATAM AIRLINES GROUP SA      SANTIAGO  LATAM AIRLINES GROUP SA   \n",
      "2894    FACTORING SECURITY SA      SANTIAGO    FACTORING SECURITY SA   \n",
      "\n",
      "     MARKET_SECTOR_DES  \n",
      "0                 Corp  \n",
      "1                 Corp  \n",
      "2                 Corp  \n",
      "3                 Corp  \n",
      "4                 Corp  \n",
      "...                ...  \n",
      "2890              Corp  \n",
      "2891              Corp  \n",
      "2892              Corp  \n",
      "2893              Corp  \n",
      "2894              Corp  \n",
      "\n",
      "[2895 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "print(step_3_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f231de",
   "metadata": {},
   "source": [
    "Only include rows that are included in the input file, but not in reference_securities.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "id": "cc4beab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_3_df = step_1_df[step_1_df['ID_BB_GLOBAL'].isin(new_securities)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "id": "eb77b260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     TICKER_YELLOW_KEY ST1 REF1  TICKER       CPN  MATURITY SERIES  \\\n",
      "1446    ED5429110 Corp   0  210  OREKON  3.500000  20281201          \n",
      "\n",
      "                    NAME   SHORT_NAME ISSUER_INDUSTRY  ... INDUSTRY_GROUP_NUM  \\\n",
      "1446  ORESUNDSKONSORTIET  ORESUNDSKON   GOVT REGIONAL  ...              20075   \n",
      "\n",
      "     INDUSTRY_SECTOR_NUM ISSUERS_STOCK INFLATION_LAG MAKE_WHOLE_CALL_SPREAD  \\\n",
      "1446               10010                           3                   N.A.   \n",
      "\n",
      "             ISSUER_BULK    ID_BB_SEC_NUM_DES FEED_SOURCE  \\\n",
      "1446  ORESUNDSKONSORTIET  OREKON 3.5 12/01/28         BGN   \n",
      "\n",
      "     ID_BB_GLOBAL_COMPANY ID_BB_GLOBAL_COMPANY_NAME  \n",
      "1446         BBG001FKN3Y7    Oresundsbro Konsortiet  \n",
      "\n",
      "[1 rows x 213 columns]\n"
     ]
    }
   ],
   "source": [
    "print(step_3_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55315774",
   "metadata": {},
   "source": [
    "Change all the columns to the reference_security columns in uppercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "id": "f19f2be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_3_correct_columns = pd.DataFrame(step_3_df, columns = reference_securities_df_upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfe5fa0",
   "metadata": {},
   "source": [
    "Lowercase the column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "id": "48579dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_3_correct_columns.columns = step_3_correct_columns.columns.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ecda41",
   "metadata": {},
   "source": [
    "Create new_securities.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "id": "a523eb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_3_correct_columns.to_csv('new_securities.csv', sep=',', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f3c3e8",
   "metadata": {},
   "source": [
    "### Step 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55237d11",
   "metadata": {},
   "source": [
    "Export to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "id": "056b167b",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_3_correct_columns.to_csv('step_4_output_part_1.csv', sep=',', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e610da43",
   "metadata": {},
   "source": [
    "Count is only here to save time, if you would like to valide that it exports a complete csv, delete the:'if count > 200: break' line\n",
    "The outputs shared in the git repository are from only the first 200 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "id": "37b04dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "step4 = pd.DataFrame(columns = ['ID_BB_GLOBAL','FIELD','VALUE', 'SOURCE','TSTAMP'])\n",
    "count = 0\n",
    "for idx, x in step_1_df.iterrows():\n",
    "    #\n",
    "#     count = count + 1\n",
    "#     if count > 200:\n",
    "#         break\n",
    "    for y in reference_fields_df['field']:\n",
    "        timestamp = datetime.now()\n",
    "        printed_time = timestamp.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "        try:\n",
    "            appendRow = {\n",
    "              'ID_BB_GLOBAL': x['ID_BB_GLOBAL'],\n",
    "              'FIELD': y,\n",
    "              'VALUE': x[y],\n",
    "              'SOURCE':'corp_pdf.dif',\n",
    "              'TSTAMP': printed_time,  \n",
    "              }\n",
    "            step4 = step4.append(appendRow, ignore_index=True)\n",
    "    \n",
    "        except:\n",
    "            appendRow = {\n",
    "              'ID_BB_GLOBAL': x['ID_BB_GLOBAL'],\n",
    "              'FIELD': y,\n",
    "              'VALUE': 'NA',\n",
    "              'SOURCE':'corp_pdf.dif',\n",
    "              'TSTAMP': printed_time,  \n",
    "              }\n",
    "            step4 = step4.append(appendRow, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "id": "7cb633d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "step4.to_csv('step_4_output_part_2.csv', sep=',', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7186fd9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe422bd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
